{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import boto3\n",
    "import logging\n",
    "import nest_asyncio\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from botocore.config import Config\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.tools import StructuredTool\n",
    "from typing import Annotated, Dict, List, Sequence, TypedDict, DefaultDict, Any, Optional\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if not logger.hasHandlers():\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of LLMs and Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(model=\"gpt-3.5-turbo-0125\", openai_api_key=OPENAI_API_KEY, temperature=0.0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge_embed_model = TextEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "openai_embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GraphState's Storage Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of a graph.\n",
    "\n",
    "    Attributes:\n",
    "        query (str): The user query\n",
    "        expanded_queries (List[str]): The expanded queries generated by the agent\n",
    "        agent (str): The agent responsible for decision making/answer generating\n",
    "        context (str): The context retrieved from the DB\n",
    "        answer (str): The answer generated by the agent\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    expanded_queries: List[str]\n",
    "    agent: str\n",
    "    context: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agents\n",
    "1. Query Expansion Agent\n",
    "2. Retrieval Agent\n",
    "3. Grading Agent\n",
    "4. Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Expands a query using LLM\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The expanded queries\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"You are a creative AI assistant specializing in expanding user queries to make them more comprehensive and diverse. Your goal is to generate multiple variant queries based on the initial user query, capturing different aspects, synonyms, related terms, and broader or narrower contexts. Ensure that the expanded queries are relevant, diverse, and avoid repetition.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Take the initial query provided by the user.\n",
    "    2. Generate 3 variant queries that explore different interpretations, related topics, or alternative phrasings.\n",
    "    3. Ensure the variants cover a range of specific to broad scopes and use synonyms or related terms.\n",
    "    4. Avoid repeating the same information or using overly similar phrasing.\n",
    "    5. Output the expanded queries in a JSON format, following the examples provided.\n",
    "    6. Do not include any preamble, explanation, or additional information beyond the expanded queries in the given JSON format.\n",
    "\n",
    "    ### Examples:\n",
    "    Query: \"machine learning algorithms\"  \n",
    "    Response:  \n",
    "    {{\n",
    "        \"expanded_queries\": [\n",
    "            \"types of machine learning algorithms\",\n",
    "            \"applications of supervised learning techniques\",\n",
    "            \"deep learning vs traditional machine learning approaches\"\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    ### Your Task:\n",
    "    - Query: \"{{query}}\"\n",
    "    - Response:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        template=prompt,\n",
    "        input_variables={\"query\": query}\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | openai | JsonOutputParser()\n",
    "    query_list = chain.invoke({\"query\": query})\n",
    "    return query_list[\"expanded_queries\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
