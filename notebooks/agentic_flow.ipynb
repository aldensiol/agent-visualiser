{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Synchronous WebCrawler is not available. Install crawl4ai[sync] for synchronous support. However, please note that the synchronous version will be deprecated soon.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import base64\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import TextEmbedding\n",
    "from IPython.display import HTML\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "from llama_index.core import PropertyGraphIndex \n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever, LLMSynonymRetriever\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "from pymilvus import (\n",
    "    model, connections, Collection, AnnSearchRequest, RRFRanker,\n",
    ")\n",
    "\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "from typing import Dict, List, Sequence, TypedDict, DefaultDict, Any, Optional\n",
    "from typing_extensions import TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if not logger.hasHandlers():\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of LLMs and Embedding Models\n",
    "1. Llama Models\n",
    "2. Normal Models\n",
    "3. Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = CLAUDE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_llama = OpenAI(model=\"gpt-3.5-turbo-0125\", openai_api_key=OPENAI_API_KEY, temperature=0.0)\n",
    "claude_llama = Anthropic(model=\"claude-3-5-sonnet-20240620\", api_key=CLAUDE_API_KEY, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.0,\n",
    "    stop=[\"\\n\\nHuman\"],\n",
    "    streaming=True,\n",
    "    stream_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0770b431a1e04e22911e0c4baa9c0759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bge_embed_model = TextEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "openai_embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "splade_embed_model = model.sparse.SpladeEmbeddingFunction(\n",
    "    model_name=\"naver/splade-cocondenser-ensembledistil\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Zillis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = os.getenv('ZILLIS_ENDPOINT')\n",
    "TOKEN = os.getenv('ZILLIS_TOKEN')\n",
    "\n",
    "connections.connect(uri=ENDPOINT, token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"vector_index\"\n",
    "collection = Collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Graph Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"15082001\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=NEO4J_USER,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    url=NEO4J_URI,\n",
    "    refresh_schema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = PropertyGraphIndex.from_existing(\n",
    "    llm = claude_llama,\n",
    "    embed_model=openai_embed_model,\n",
    "    property_graph_store=graph_store,\n",
    ")\n",
    "\n",
    "vector_retriever = VectorContextRetriever(\n",
    "  index.property_graph_store,\n",
    "  vector_store=index.vector_store,\n",
    "  embed_model=openai_embed_model,\n",
    ")\n",
    "\n",
    "keyword_retriever = LLMSynonymRetriever(\n",
    "    index.property_graph_store, \n",
    "    llm=claude_llama,\n",
    "    path_depth=1,\n",
    ")\n",
    "\n",
    "kg_retriever = index.as_retriever(sub_retrievers=[vector_retriever, keyword_retriever])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GraphState's Storage Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_defaultdicts(d1, d2):\n",
    "    # Create a new defaultdict of lists\n",
    "    merged = defaultdict(str)\n",
    "    for key, value in d1.items():\n",
    "        merged[key] = value\n",
    "    for key, value in d2.items():\n",
    "        merged[key] = value\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of a graph.\n",
    "\n",
    "    Attributes:\n",
    "        query (str): The user query\n",
    "        query_list (List[str]): The expanded list of queries based on the user query\n",
    "        agent (str): The agent responsible for decision making/answer generating\n",
    "        --- DEPRECATED --- contexts (DefaultDict[str, str]): The contexts retrieved. Keys are \"kg\" or \"db\" indicating the source of the context, and values are the contexts themselves.\n",
    "        kg_context (str): The context retrieved from the knowledge graph\n",
    "        db_context (str): The context retrieved from the vector database\n",
    "        websearch_context (str): The context retrieved from the web search\n",
    "        metrics (DefaultDict[str, str]): The numerical evaluations of metrics, such as \"correctness\", \"relevance\", \"clarity\", etc.\n",
    "        reasons (DefaultDict[str, str]): The reasons for the the metrics. Keys are the metric names, and values are the reasons.\n",
    "        answer (str): The answer generated by the agent\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    query_list: List[str]\n",
    "    agent: str\n",
    "    # contexts: Annotated[DefaultDict[str, str], reduce_defaultdicts]\n",
    "    kg_context: str\n",
    "    db_context: str\n",
    "    websearch_context: str\n",
    "    metrics: DefaultDict[str, str]\n",
    "    reasons: DefaultDict[str, str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "1. search_kg_db (retrieves context from KG according to query)\n",
    "2. search_vector_db (retrieves context from a traditional vector DB according to query)\n",
    "3. get_kg_context (uses parallel processing to retrieve all contexts required from a query list, and formats it -- kg)\n",
    "4. get_db_context (uses parallel processing to retrieve all contexts required from a query list, and formats it -- vector DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_kg_db(query: str, retriever) -> str:\n",
    "    \"\"\"\n",
    "    Helper Function to retrieve context from KG a single query\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the knowledge graph\n",
    "    \"\"\"\n",
    "    return f\"{retriever.get_context(query)}\"\n",
    "\n",
    "def search_vector_db(query: str, retriever) -> str:\n",
    "    \"\"\"\n",
    "    Helper Function to retrieve context from KG a single query\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the knowledge graph\n",
    "    \"\"\"\n",
    "    return f\"{retriever.get_context(query)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kg_context(queries: List[str], retriever) -> str:\n",
    "    \"\"\"\n",
    "    Uses parallel processing to retrieve context from the KG for a list of queries.\n",
    "\n",
    "    Args:\n",
    "        query_list (List[str]): The list of user queries\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the knowledge graph\n",
    "    \"\"\"\n",
    "\n",
    "    context = []\n",
    "        \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_query = {executor.submit(search_kg_db, query, retriever): query for query in queries}\n",
    "        for future in as_completed(future_to_query):\n",
    "            query = future_to_query[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                context.append(result)\n",
    "            except Exception as exc:\n",
    "                print(f\"Query {query} generated an exception: {exc}\")\n",
    "\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "def get_db_context(queries: List[str], retriever) -> str:\n",
    "    \"\"\"\n",
    "    Uses parallel processing to retrieve context from a Vector DB for a list of queries.\n",
    "\n",
    "    Args:\n",
    "        queries (List[str]): The list of user queries\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the DB\n",
    "    \"\"\"\n",
    "    \n",
    "    context = []\n",
    "        \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_query = {executor.submit(search_vector_db, query, retriever): query for query in queries}\n",
    "        for future in as_completed(future_to_query):\n",
    "            query = future_to_query[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                context.append(result)\n",
    "            except Exception as exc:\n",
    "                print(f\"Query {query} generated an exception: {exc}\")\n",
    "\n",
    "    return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agents\n",
    "1. Retrieval Agent (retrieves from kg_db and vector_db)\n",
    "2. Answer Generation Agent (uses context from vector_db to generate answer)\n",
    "3. Grading Agent (grades previously generated answer)\n",
    "4. Display Subgraph Agent (multi hops for context expansion)\n",
    "5. Refine Answer Agent (uses context retrieved from kg_db to refine previous answer)\n",
    "6. Regrading Agent (regrades the final answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Expands a query using LLM\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The expanded queries\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<system>\n",
    "    You are a creative AI assistant specializing in expanding user queries to make them more comprehensive and diverse. Your goal is to generate multiple variant queries based on the initial user query, capturing different aspects, synonyms, related terms, and broader or narrower contexts. Ensure that the expanded queries are relevant, diverse, and avoid repetition.\n",
    "    </system>\n",
    "\n",
    "    <instructions>\n",
    "    1. Take the initial query provided by the user.\n",
    "    2. Generate 2 variant queries that explore different interpretations, related topics, or alternative phrasings.\n",
    "    3. Ensure the variants cover a range of specific to broad scopes and use synonyms or related terms.\n",
    "    4. Avoid repeating the same information or using overly similar phrasing.\n",
    "    5. Output the expanded queries in a JSON format, following the examples provided.\n",
    "    6. Do not include any preamble, explanation, or additional information beyond the expanded queries in the given JSON format.\n",
    "    </instructions>\n",
    "\n",
    "    <example_output>\n",
    "    Query: \"machine learning algorithms\"\n",
    "    {{\n",
    "        \"query_list\": [\n",
    "            \"types of machine learning algorithms\",\n",
    "            \"applications of supervised learning techniques\",\n",
    "        ]\n",
    "    }}\n",
    "    <example_output>\n",
    "\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "    \n",
    "    <response>\n",
    "    [Your JSON only response here]\n",
    "    </response>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=prompt\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | claude | JsonOutputParser()\n",
    "    query_list = chain.invoke({\"query\": query})\n",
    "    return query_list[\"query_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_expansion_tool = StructuredTool.from_function(\n",
    "    func=query_expansion,\n",
    "    name=\"Query Expansion\",\n",
    "    description=\"Expands a query using LLM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that expands the user query\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    query_list = query_expansion_tool.invoke(state[\"query\"])\n",
    "    return {\"query_list\": query_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_db(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves context from a conventional Vector DB, given a list of queries.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from Vector DB\n",
    "    \"\"\"\n",
    "    \n",
    "    dense_embedding = list(bge_embed_model.query_embed(query))[0]\n",
    "    sparse_embedding = list(splade_embed_model.encode_queries([query]))\n",
    "    \n",
    "    search_results = collection.hybrid_search(\n",
    "            reqs=[\n",
    "                AnnSearchRequest(\n",
    "                    data=[dense_embedding],  # content vector embedding\n",
    "                    anns_field='dense_embeddings',  # content vector field\n",
    "                    param={\"metric_type\": \"COSINE\", \"params\": {\"M\": 64, \"efConstruction\": 512}}, # Search parameters\n",
    "                    limit=3\n",
    "                ),\n",
    "                AnnSearchRequest(\n",
    "                    data=list(sparse_embedding),  # keyword vector embedding\n",
    "                    anns_field='sparse_embeddings',  # keyword vector field\n",
    "                    param={\"metric_type\": \"IP\", \"params\": {\"drop_ratio_build\": 0.2}}, # Search parameters\n",
    "                    limit=3\n",
    "                )\n",
    "            ],\n",
    "            output_fields=['doc_id', 'text', 'doc_source'],\n",
    "            rerank=RRFRanker(),\n",
    "            limit=3\n",
    "            )\n",
    "    \n",
    "    hits = search_results[0]\n",
    "    \n",
    "    context = []\n",
    "    for res in hits:\n",
    "        text = res.text\n",
    "        source = res.doc_source\n",
    "        context.append(f\"Source: {source}\\nContext: {text}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "async def retrieve_db_async(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves context from a conventional Vector DB, given a list of queries.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from Vector DB\n",
    "    \"\"\"\n",
    "    \n",
    "    dense_embedding = list(bge_embed_model.query_embed(query))[0]\n",
    "    sparse_embedding = list(splade_embed_model.encode_queries([query]))\n",
    "    \n",
    "    search_results = collection.hybrid_search(\n",
    "            reqs=[\n",
    "                AnnSearchRequest(\n",
    "                    data=[dense_embedding],  # content vector embedding\n",
    "                    anns_field='dense_embeddings',  # content vector field\n",
    "                    param={\"metric_type\": \"COSINE\", \"params\": {\"M\": 64, \"efConstruction\": 512}}, # Search parameters\n",
    "                    limit=3\n",
    "                ),\n",
    "                AnnSearchRequest(\n",
    "                    data=list(sparse_embedding),  # keyword vector embedding\n",
    "                    anns_field='sparse_embeddings',  # keyword vector field\n",
    "                    param={\"metric_type\": \"IP\", \"params\": {\"drop_ratio_build\": 0.2}}, # Search parameters\n",
    "                    limit=3\n",
    "                )\n",
    "            ],\n",
    "            output_fields=['doc_id', 'text', 'doc_source'],\n",
    "            rerank=RRFRanker(),\n",
    "            limit=3\n",
    "            )\n",
    "    \n",
    "    hits = search_results[0]\n",
    "    \n",
    "    context = []\n",
    "    for res in hits:\n",
    "        text = res.text\n",
    "        source = res.doc_source\n",
    "        context.append(f\"Source: {source}\\nContext: {text}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_db_tool = StructuredTool.from_function(\n",
    "    func=retrieve_db,\n",
    "    coroutine=retrieve_db_async,\n",
    "    name=\"Retrieve Vector DB\",\n",
    "    description=\"Retrieves context from a conventional Vector DB, given a list of queries.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_db_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that retrieves context from a Vector DB\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    logger.info(\"------- Retrieving Context Via Vector DB -------\")\n",
    "    context = retrieve_db_tool.invoke({\"query\": state[\"query\"]})\n",
    "    return {\"db_context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_kg(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves context from the ingested knowledge graph, given a list of queries.\n",
    "    Processes queries in parallel using ThreadPoolExecutor.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the knowledge graph\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = kg_retriever.retrieve(query)\n",
    "    context = '\\n\\n'.join([node.text for node in nodes])\n",
    "    return context\n",
    "\n",
    "async def retrieve_kg_async(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves context from the ingested knowledge graph, given a list of queries.\n",
    "    Processes queries in parallel using ThreadPoolExecutor.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the knowledge graph\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = kg_retriever.retrieve(query)\n",
    "    context = '\\n\\n'.join([node.text for node in nodes])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_kg_tool = StructuredTool.from_function(\n",
    "    func=retrieve_kg,\n",
    "    coroutine=retrieve_kg_async,\n",
    "    name=\"Retrieve Knowledge Graph\",\n",
    "    description=\"Retrieves context from the ingested knowledge graph, given a list of queries\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_kg_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that retrieves context from the ingested knowledge graph\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    logger.info(\"------- Retrieving Context Via KG DB -------\")\n",
    "    context = retrieve_kg_tool.invoke({\"query\": state[\"query\"]})\n",
    "    return {\"kg_context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def websearch(query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves context from the web using SerpAPI for search and AsyncWebCrawler for content\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "        num_results (int): Number of top results to crawl (default: 3)\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted context retrieved from the websearch\n",
    "    \"\"\"\n",
    "    logger.info(\"------- Retrieving Context Via Web Search -------\")\n",
    "    # Use SerpAPI to get search results\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"num\": num_results,\n",
    "        \"api_key\": os.getenv(\"SERPAPI_API_KEY\")\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    \n",
    "    # Extract URLs from search results\n",
    "    urls = [result['link'] for result in results.get('organic_results', [])[:num_results]]\n",
    "    \n",
    "    # Crawl each URL using AsyncWebCrawler\n",
    "    contents = []\n",
    "    for url in urls:\n",
    "        async with AsyncWebCrawler(verbose=True) as crawler:\n",
    "            result = await crawler.arun(url=url)\n",
    "        \n",
    "        # Extract relevant information from the crawled content\n",
    "        content = clean_content(result.markdown)\n",
    "        content = content[:3000]\n",
    "        contents.append(f\"URL: {url}\\nContent:\\n{content}\\n\\n\")\n",
    "\n",
    "    return \"\".join(contents)\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_content(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the content by removing images, HTML links, and useless information.\n",
    "    \"\"\"\n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Remove image descriptions (usually in square brackets)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove common useless phrases (customize this list as needed)\n",
    "    useless_phrases = [\n",
    "        \"Click here\",\n",
    "        \"Read more\",\n",
    "        \"Learn more\",\n",
    "        \"Sign up\",\n",
    "        \"Subscribe\",\n",
    "        \"Cookie policy\",\n",
    "        \"Privacy policy\",\n",
    "        \"Terms of service\",\n",
    "    ]\n",
    "    for phrase in useless_phrases:\n",
    "        text = text.replace(phrase, '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_tool = StructuredTool.from_function(\n",
    "    func=websearch,\n",
    "    coroutine=websearch,\n",
    "    name=\"Websearch Tool\",\n",
    "    description=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def websearch_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that retrieves context from a websearch\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    logger.info(\"------- Retrieving Context Via Websearch -------\")\n",
    "    context = await websearch_tool.ainvoke({\"query\": state[\"query\"]})\n",
    "    return {\"websearch_context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_answer(query: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an answer to the user query from the Vector DB context\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "        context (str): The context retrieved from the Vector DB\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the agent\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<system>\n",
    "    You are an AI assistant that specializes in generating answers based on the provided context. Your goal is to provide a concise and informative response to the user's query by extracting relevant information from the given context.\n",
    "    </system>\n",
    "    \n",
    "    <instruction>\n",
    "    1. Understand the Query: Carefully read and understand the user's query to identify the key information required.\n",
    "    2. Extract Relevant Information: Identify the most relevant parts of the provided context that directly answer the user's query. Only answer based on the context given.\n",
    "    3. Conciseness and Clarity: Generate a response that is clear, concise, and directly addresses the user's question without including unnecessary information.\n",
    "    4. Completeness: Ensure the answer covers all aspects of the query as much as possible based on the provided context.\n",
    "    5. Neutral and Informative Tone: Provide the answer in a neutral, professional tone, ensuring factual accuracy.\n",
    "    6. Stay Direct and Focused: Provide a straightforward answer without any introductory remarks, elaborations, or additional comments that do not pertain to the query.\n",
    "    7. Do not include sentences such as: \"Based on the context\" or \"Based on the information provided\".\n",
    "    </instruction>\n",
    "    \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <response>\n",
    "    [Your response here]\n",
    "    </response>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"context\"],\n",
    "        template=prompt\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | claude | StrOutputParser()\n",
    "    response = await chain.ainvoke({\"query\": query, \"context\": context})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answer_tool = StructuredTool.from_function(\n",
    "    func=generate_answer,\n",
    "    coroutine=generate_answer,\n",
    "    name=\"DB Answer Generator\",\n",
    "    description=\"Generates an answer to the user query from the Vector DB context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_answer_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that generates an answer to the user query from the Vector DB context\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        state (GraphState): The updated state of the graph\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    db_context = state[\"db_context\"]\n",
    "    kg_context = state[\"kg_context\"]\n",
    "    context = db_context + kg_context\n",
    "    \n",
    "    logger.info(\"------- Generating Answer -------\")\n",
    "    response = await generate_answer_tool.ainvoke({\"query\": query, \"context\": context})\n",
    "    logger.info(f\"Generated Answer: {response}\")\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grader(query: str, answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Grades the answers based on Answer Relevancy, Completeness,  to the query\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The preferred context based on the grading criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<system>\n",
    "    You are an expert evaluator specializing in critically assessing the quality of text responses based on specific criteria. Your role is to provide detailed and evidence-based evaluations for each criterion below.\n",
    "    </system>\n",
    "\n",
    "    <instructions>\n",
    "    - Evaluation Criteria: Assess the provided answer according to the following four metrics:\n",
    "    1. Answer Relevancy: Focus on how directly the answer addresses the query. If the answer mentions a lack of relevant context or fails to engage with the query (even partially), it should be rated low. Full engagement with the query should be rewarded, even in the face of limited context.\n",
    "    2. Completeness: Evaluate whether the answer provides a comprehensive response. If the answer avoids critical aspects of the query, such as by deflecting with statements like \"the context does not provide enough information,\" mark it down heavily. The answer should attempt to provide all necessary details, even if they are inferred.\n",
    "    3. Clarity and Coherence: Review the logical flow, structure, and readability of the answer. Is it clearly written, logically organized, and easy to follow? Even if the content is incorrect, clarity of presentation should still be considered.\n",
    "    4. Correctness: Fact-check the information. Are there any inaccuracies, errors, or misleading statements in the answer? Any significant factual mistakes should result in a low score.\n",
    "\n",
    "    - Scoring System: Assign a numerical score from 1 to 10 for each metric (with 1 being the lowest and 10 being the highest). Use only whole numbers.\n",
    "\n",
    "    - Detailed Explanation: For each metric, provide a detailed explanation justifying the score. Refer to specific parts of the answer to explain why it scored high or low, using evidence-based reasoning.\n",
    "\n",
    "    - Output Format: Return the evaluation strictly in the JSON format below. Ensure that all fields are correctly filled, and the format is followed exactly as specified.\n",
    "\n",
    "    - Guidelines: \n",
    "        1. Penalize answers that deflect or fail to engage with the query.\n",
    "        2. Answers should receive low marks on Relevancy and Completeness if they simply point out insufficient context rather than attempting to address the question.\n",
    "        3. Strictly follow the output format and ensure there are no deviations from the requested structure.\n",
    "    </instructions>\n",
    "\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    <answer>\n",
    "    {answer}\n",
    "    </answer>\n",
    "\n",
    "    <output_format>\n",
    "    {{\n",
    "        \"evaluation\": {{\n",
    "            \"relevance\": 10,\n",
    "            \"completeness\": 9,\n",
    "            \"coherence\": 8,\n",
    "            \"correctness\": 7\n",
    "        }},\n",
    "        \"reasoning\": {{\n",
    "            \"relevance\": \"The answer is highly relevant to the query, directly addressing the question with a specific focus on the required topics.\",\n",
    "            \"completeness\": \"While the answer covers most necessary aspects, it lacks detail on a few minor points, which could enhance the response.\",\n",
    "            \"coherence\": \"The answer is generally clear and follows a logical structure, but there are a few sentences that could be more concise.\",\n",
    "            \"correctness\": \"There are some inaccuracies in the data provided, particularly concerning the explanation of key terms.\"\n",
    "        }}\n",
    "    }}\n",
    "    </output_format>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"answer\"],\n",
    "        template=prompt\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | claude | JsonOutputParser()\n",
    "    result = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "    logger.info(f\"Grading Result: {result}\")\n",
    "    return result\n",
    "\n",
    "async def grader_async(query: str, answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Grades the answers based on Answer Relevancy, Completeness,  to the query\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query\n",
    "\n",
    "    Returns:\n",
    "        str: The preferred context based on the grading criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<system>\n",
    "    You are an expert evaluator specializing in critically assessing the quality of text responses based on specific criteria. Your role is to provide detailed and evidence-based evaluations for each criterion below.\n",
    "    </system>\n",
    "\n",
    "    <instructions>\n",
    "    - Evaluation Criteria: Assess the provided answer according to the following four metrics:\n",
    "    1. Answer Relevancy: Focus on how directly the answer addresses the query. If the answer mentions a lack of relevant context or fails to engage with the query (even partially), it should be rated low. Full engagement with the query should be rewarded, even in the face of limited context.\n",
    "    2. Completeness: Evaluate whether the answer provides a comprehensive response. If the answer avoids critical aspects of the query, such as by deflecting with statements like \"the context does not provide enough information,\" mark it down heavily. The answer should attempt to provide all necessary details, even if they are inferred.\n",
    "    3. Clarity and Coherence: Review the logical flow, structure, and readability of the answer. Is it clearly written, logically organized, and easy to follow? Even if the content is incorrect, clarity of presentation should still be considered.\n",
    "    4. Correctness: Fact-check the information. Are there any inaccuracies, errors, or misleading statements in the answer? Any significant factual mistakes should result in a low score.\n",
    "\n",
    "    - Scoring System: Assign a numerical score from 1 to 10 for each metric (with 1 being the lowest and 10 being the highest). Use only whole numbers.\n",
    "\n",
    "    - Detailed Explanation: For each metric, provide a detailed explanation justifying the score. Refer to specific parts of the answer to explain why it scored high or low, using evidence-based reasoning.\n",
    "\n",
    "    - Output Format: Return the evaluation strictly in the JSON format below. Ensure that all fields are correctly filled, and the format is followed exactly as specified.\n",
    "\n",
    "    - Guidelines: \n",
    "        1. Penalize answers that deflect or fail to engage with the query.\n",
    "        2. Answers should receive low marks on Relevancy and Completeness if they simply point out insufficient context rather than attempting to address the question.\n",
    "        3. Strictly follow the output format and ensure there are no deviations from the requested structure.\n",
    "    </instructions>\n",
    "\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    <answer>\n",
    "    {answer}\n",
    "    </answer>\n",
    "\n",
    "    <output_format>\n",
    "    {{\n",
    "        \"evaluation\": {{\n",
    "            \"relevance\": 10,\n",
    "            \"completeness\": 9,\n",
    "            \"coherence\": 8,\n",
    "            \"correctness\": 7\n",
    "        }},\n",
    "        \"reasoning\": {{\n",
    "            \"relevance\": \"The answer is highly relevant to the query, directly addressing the question with a specific focus on the required topics.\",\n",
    "            \"completeness\": \"While the answer covers most necessary aspects, it lacks detail on a few minor points, which could enhance the response.\",\n",
    "            \"coherence\": \"The answer is generally clear and follows a logical structure, but there are a few sentences that could be more concise.\",\n",
    "            \"correctness\": \"There are some inaccuracies in the data provided, particularly concerning the explanation of key terms.\"\n",
    "        }}\n",
    "    }}\n",
    "    </output_format>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"answer\"],\n",
    "        template=prompt\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | claude | JsonOutputParser()\n",
    "    result = await chain.ainvoke({\"query\": query, \"answer\": answer})\n",
    "    logger.info(f\"Grading Result: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader_tool = StructuredTool.from_function(\n",
    "    func=grader,\n",
    "    coroutine=grader_async,\n",
    "    name=\"Grader\",\n",
    "    description=\"Grades the contexts retrieved from KG and DB sources based on relevance and quality to the query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def grader_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent that grades the contexts retrieved from KG and conventional sources\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"------- Grading Answer -------\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    answer = state[\"answer\"]\n",
    "    result = grader_tool.invoke({\"query\": query, \"answer\": answer})\n",
    "    evaluation, reasoning = result['evaluation'], result['reasoning']\n",
    "    \n",
    "    relevance, completeness, coherence, correctness = evaluation[\"relevance\"], evaluation[\"completeness\"], evaluation[\"coherence\"], evaluation[\"correctness\"]\n",
    "    reason_relevance, reason_completeness, reason_coherence, reason_correctness = reasoning[\"relevance\"], reasoning[\"completeness\"], reasoning[\"coherence\"], reasoning[\"correctness\"]\n",
    "    \n",
    "    metrics, reasons = state[\"metrics\"], state[\"reasons\"]\n",
    "    metrics[\"relevance\"], metrics[\"completeness\"], metrics[\"coherence\"], metrics[\"correctness\"] = relevance, completeness, coherence, correctness\n",
    "    reasons[\"relevance\"], reasons[\"completeness\"], reasons[\"coherence\"], reasons[\"correctness\"] = reason_relevance, reason_completeness, reason_coherence, reason_correctness\n",
    "    \n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"reasons\": reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_metrics_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Checks the metrics of the answer generated and decides if they are good enough\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: The updated state of the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"------- Deciding If Requires Extra Context from KG -------\")\n",
    "    metrics_scores = state[\"metrics\"]\n",
    "    logger.info(f\"Metric Scores: {metrics_scores}\")\n",
    "    for metric, score in metrics_scores.items():\n",
    "        if score <= 7:\n",
    "            return \"not good enough\"\n",
    "    return \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def refine_answer(query: str, answer: str, websearch_context: str) -> str:\n",
    "    \"\"\"\n",
    "    Refines the initial answer using context retrieved from Websearch\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query \n",
    "        answer (str): The initial answer generated\n",
    "        Websearch (str): The context retrieved from the Websearch\n",
    "\n",
    "    Returns:\n",
    "        str: The refined answer\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<system>\n",
    "    You are an expert answer refiner with access to both the initial answer and additional context from a Websearch. Your task is to enhance the initial answer using the additional context provided while maintaining logical coherence, relevance, completeness, and correctness. Ensure that the refined answer is comprehensive, factually accurate, and directly addresses the query.\n",
    "    </system>\n",
    "\n",
    "    <instructions>\n",
    "    - Review the initial answer provided in response to the query. Identify areas where the answer could be more detailed, accurate, or relevant.\n",
    "    - Incorporate relevant information from the Websearch context to improve the answer. Ensure that the added information directly supports or expands upon the initial answer without deviating from the main topic of the query.\n",
    "    - Maintain a clear and logical flow in the refined answer. Avoid redundancy and ensure that the enhanced content is seamlessly integrated with the existing text.\n",
    "    - The refined answer should be concise yet comprehensive, covering all aspects of the query as fully as possible with the available context.\n",
    "    - Ensure that all statements in the refined answer are factually accurate and derived from either the initial answer or the Websearch context. Avoid introducing unsupported or speculative information.\n",
    "    - Do not include any preamble or additional commentary. Return only the refined answer text in a natural and fluent style.\n",
    "    </instructions>\n",
    "\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    <initial_answer>\n",
    "    {answer}\n",
    "    </initial_answer>\n",
    "\n",
    "    <context>\n",
    "    {websearch_context}\n",
    "    </context>\n",
    "\n",
    "    <refined_answer>\n",
    "    [Your refined answer here]\n",
    "    </refined_answer>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"answer\", \"websearch_context\"],\n",
    "        template=prompt\n",
    "    )\n",
    "    \n",
    "    chain = prompt_template | claude | StrOutputParser()\n",
    "    response = await chain.ainvoke({\"query\": query, \"answer\": answer, \"websearch_context\": websearch_context})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_answer_tool = StructuredTool.from_function(\n",
    "    func=refine_answer,\n",
    "    coroutine=refine_answer,\n",
    "    name=\"Answer Refiner\",\n",
    "    description=\"Refines the initial answer using context retrieved from the Websearch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def refine_answer_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Utilises KG Context to refine initial answer\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        state (GraphState): The updated state of the graph\n",
    "    \"\"\"\n",
    "    logger.info(\"------- Refining Answer with KG Context -------\")\n",
    "    query = state[\"query\"]\n",
    "    answer = state[\"answer\"]\n",
    "    websearch_context = state[\"websearch_context\"]\n",
    "    refined_answer = await refine_answer_tool.ainvoke({\"query\": query, \"answer\": answer, \"websearch_context\": websearch_context})\n",
    "    return {\"answer\": refined_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Dummy agent that does nothing\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): The state of the graph\n",
    "\n",
    "    Returns:\n",
    "        GraphState: Unchanged state of the graph\n",
    "    \"\"\"\n",
    "    return {\"answer\": state[\"answer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph():\n",
    "    builder = StateGraph(GraphState)\n",
    "\n",
    "    builder.add_node(\"search_kg_db\", retrieve_kg_agent)\n",
    "    builder.add_node(\"search_vector_db\", retrieve_db_agent)\n",
    "    builder.add_node(\"generate_answer\", generate_answer_agent)\n",
    "    builder.add_node(\"grader\", grader_agent)\n",
    "    builder.add_node(\"websearch\", websearch_agent)\n",
    "    builder.add_node(\"refine_answer\", refine_answer_agent)\n",
    "    \n",
    "    builder.add_edge(START, \"search_vector_db\")\n",
    "    builder.add_edge(START, \"search_kg_db\")\n",
    "\n",
    "    builder.add_edge([\"search_kg_db\", \"search_vector_db\"], \"generate_answer\")\n",
    "    builder.add_edge(\"generate_answer\", \"grader\")\n",
    "\n",
    "    builder.add_conditional_edges(\n",
    "        \"grader\",\n",
    "        decide_metrics_agent,\n",
    "        {\n",
    "            \"good\": END,\n",
    "            \"not good enough\": \"websearch\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    builder.add_edge(\"websearch\", \"refine_answer\")\n",
    "\n",
    "    builder.add_edge(\"refine_answer\", \"grader\")\n",
    "\n",
    "    graph = builder.compile()\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: center;\">\n",
       "    <img src=\"data:image/png;base64,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\" width=\"400\" height=\"auto\"/>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_png = graph.get_graph().draw_mermaid_png(\n",
    "    curve_style=CurveStyle.LINEAR,\n",
    "    wrap_label_n_words=4,\n",
    "    output_file_path=None,\n",
    "    draw_method=MermaidDrawMethod.API,\n",
    "    background_color=\"#000000\",\n",
    "    padding=10,\n",
    ")\n",
    "\n",
    "graph_base64 = base64.b64encode(graph_png).decode(\"utf-8\")\n",
    "\n",
    "HTML(f'''\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"data:image/png;base64,{graph_base64}\" width=\"400\" height=\"auto\"/>\n",
    "</div>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query The Workflow\n",
    "1. Synchronous\n",
    "2. Streamified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_INPUTS = {\n",
    "    \"query\": \"\",\n",
    "    \"agent\": \"\",\n",
    "    \"kg_context\": \"\",\n",
    "    \"db_context\": \"\",\n",
    "    \"websearch_context\": \"\",\n",
    "    \"metrics\": defaultdict(str),\n",
    "    \"reasons\": defaultdict(str),\n",
    "    \"answer\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ------- Retrieving Context Via KG DB -------\n",
      "INFO - ------- Retrieving Context Via Vector DB -------\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO - ------- Generating Answer -------\n",
      "INFO - Generated Answer: The provided context does not contain information specifically addressing the long-term neurological and cardiovascular effects of chronic sleep deprivation in shift workers or healthcare professionals. The context primarily focuses on diabetes management, pre-diabetes, and insulin therapy. It does not discuss sleep deprivation or its effects on shift workers or healthcare professionals.\n",
      "INFO - ------- Grading Answer -------\n",
      "INFO - Grading Result: {'evaluation': {'relevance': 2, 'completeness': 1, 'coherence': 8, 'correctness': 9}, 'reasoning': {'relevance': 'The answer is barely relevant to the query. It immediately states that the provided context does not contain information about the topic asked. While this honesty is appreciated, it fails to engage with the question at all, resulting in a very low relevance score.', 'completeness': 'The answer is entirely incomplete. It does not attempt to address any aspect of the question about long-term neurological and cardiovascular effects of chronic sleep deprivation in shift workers. Instead, it simply states a lack of information and mentions unrelated topics like diabetes management. This complete failure to engage with the query results in the lowest possible completeness score.', 'coherence': \"Despite its lack of relevance and completeness, the answer is clearly written and logically structured. It clearly communicates what information is (and isn't) available in the context. The sentence structure and flow are appropriate, making it easy to understand.\", 'correctness': \"The information provided in the answer appears to be factually correct. It accurately states that the context does not contain the requested information and correctly identifies the topics that are present in the context (diabetes management, pre-diabetes, and insulin therapy). While it doesn't address the query, what it does say is not incorrect.\"}}\n",
      "INFO - ------- Deciding If Requires Extra Context from KG -------\n",
      "INFO - Metric Scores: defaultdict(<class 'str'>, {'relevance': 2, 'completeness': 1, 'coherence': 8, 'correctness': 9})\n",
      "INFO - ------- Retrieving Context Via Websearch -------\n",
      "INFO - ------- Retrieving Context Via Web Search -------\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 🌤️  Warming up the AsyncWebCrawler\n",
      "[LOG] 🌞 AsyncWebCrawler is ready to crawl\n",
      "[LOG] 🚀 Content extracted for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3971766/, success: True, time taken: 0.13 seconds\n",
      "[LOG] 🚀 Extraction done for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3971766/, time taken: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 🌤️  Warming up the AsyncWebCrawler\n",
      "[LOG] 🌞 AsyncWebCrawler is ready to crawl\n",
      "[LOG] 🚀 Content extracted for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629843/, success: True, time taken: 0.09 seconds\n",
      "[LOG] 🚀 Extraction done for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629843/, time taken: 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO - ------- Refining Answer with KG Context -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 🌤️  Warming up the AsyncWebCrawler\n",
      "[LOG] 🌞 AsyncWebCrawler is ready to crawl\n",
      "[LOG] 🚀 Content extracted for https://www.sciencedirect.com/science/article/abs/pii/B9780444626271000238, success: True, time taken: 0.00 seconds\n",
      "[LOG] 🚀 Extraction done for https://www.sciencedirect.com/science/article/abs/pii/B9780444626271000238, time taken: 0.00 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ------- Grading Answer -------\n",
      "INFO - Grading Result: {'evaluation': {'relevance': 10, 'completeness': 9, 'coherence': 10, 'correctness': 9}, 'reasoning': {'relevance': 'The answer is highly relevant to the query, directly addressing both the neurological and cardiovascular effects of chronic sleep deprivation in shift workers, with a specific focus on healthcare professionals. It engages fully with all aspects of the question, providing a comprehensive overview of the potential long-term effects.', 'completeness': \"The response is very comprehensive, covering a wide range of neurological and cardiovascular effects. It also includes additional health risks and mentions the specific statistic about healthcare workers not getting enough sleep. However, it could have provided more detailed information on some of the long-term neurological effects, such as potential impacts on memory or cognitive decline, which is why it doesn't receive a perfect score.\", 'coherence': 'The answer is exceptionally well-structured and easy to follow. It begins with a clear introduction, then systematically addresses neurological effects, cardiovascular effects, and additional health risks. Each point is clearly articulated and logically flows from one to the next. The use of numbered lists enhances readability and organization.', 'correctness': 'The information provided appears to be largely accurate and well-supported by current understanding of the effects of shift work and sleep deprivation. The inclusion of specific effects like reduced cognitive performance, increased risk of cardiovascular diseases, and metabolic disturbances aligns with established research. However, the 32% statistic for healthcare workers not getting enough sleep is presented without a source, which slightly impacts the perfect correctness score.'}}\n",
      "INFO - ------- Deciding If Requires Extra Context from KG -------\n",
      "INFO - Metric Scores: defaultdict(<class 'str'>, {'relevance': 10, 'completeness': 9, 'coherence': 10, 'correctness': 9})\n"
     ]
    }
   ],
   "source": [
    "user_queries = [\"what are the potential long-term neurological and cardiovascular effects of chronic sleep deprivation in shift workers, particularly those in healthcare professions.\"]\n",
    "\n",
    "inputs = BASE_INPUTS.copy()\n",
    "\n",
    "for query in user_queries:\n",
    "    inputs[\"query\"] = query\n",
    "\n",
    "    results = await graph.ainvoke(inputs)\n",
    "    \n",
    "    final_answer = results.get(\"answer\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronic sleep deprivation in shift workers, particularly those in healthcare professions, can have significant long-term neurological and cardiovascular effects. Based on the available context, here's an overview of the potential impacts:\n",
      "\n",
      "Neurological effects:\n",
      "1. Reduced cognitive performance: Shift work and long work hours increase the risk of fatigue-related errors and reduced performance on the job.\n",
      "2. Sleep disturbances: Shift workers often experience short sleep duration and sleep disturbances, which can lead to chronic sleep deprivation.\n",
      "3. Increased risk of injuries: Fatigue from shift work and long hours can increase the likelihood of workplace accidents and injuries.\n",
      "\n",
      "Cardiovascular effects:\n",
      "1. Increased risk of cardiovascular diseases: Shift work is associated with a higher risk of developing a wide range of chronic diseases, including cardiovascular conditions.\n",
      "2. Obesity: Shift workers are at an increased risk of obesity, which is a known risk factor for cardiovascular diseases.\n",
      "3. Metabolic disturbances: Disruption of circadian rhythms due to shift work can lead to metabolic changes that may contribute to cardiovascular problems.\n",
      "\n",
      "Additional health risks:\n",
      "1. Chronic diseases: Shift work and long work hours are linked to an increased risk of various chronic diseases beyond cardiovascular conditions.\n",
      "2. Fatigue-related errors: In healthcare settings, this can lead to compromised patient safety and increased medical errors.\n",
      "\n",
      "It's important to note that 32% of healthcare workers report not getting enough sleep, which exacerbates these risks. Healthcare organizations need to consider these potential long-term effects when designing work schedules and implementing strategies to mitigate the negative impacts of shift work on their employees' health and well-being.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
